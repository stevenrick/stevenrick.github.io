[
	{
		"id": "http://zotero.org/users/1296135/items/4Q4IMENP",
		"type": "paper-conference",
		"abstract": "Designers often struggle to sufficiently explore large design spaces, which can lead to design fixation and suboptimal outcomes. Here we introduce DesignAID, a generative AI tool that supports broader design space exploration by first using large language models to produce a range of diverse ideas expressed in words, and then using image generation software to create images from these words. This innovative combination of AI-based capabilities allows human-computer pairs to rapidly create a diverse set of visual concepts without time-consuming drawing. In a study with 87 crowd-sourced designers, we found that designers rated the automatic generation of images from words as significantly more inspirational, enjoyable, and useful than a conventional baseline condition of image search using Pinterest. Surprisingly, however, we found that automatically generating highly diverse ideas had less value. For image generation, the high diversity condition was somewhat better in inspiration but no better in the other dimensions, and for image search it was significantly worse in all dimensions.",
		"collection-title": "CI '23",
		"container-title": "Proceedings of The ACM Collective Intelligence Conference",
		"DOI": "10.1145/3582269.3615596",
		"event-place": "New York, NY, USA",
		"ISBN": "9798400701139",
		"license": "All rights reserved",
		"page": "1–11",
		"publisher": "Association for Computing Machinery",
		"publisher-place": "New York, NY, USA",
		"source": "ACM Digital Library",
		"title": "DesignAID: Using Generative AI and Semantic Diversity for Design Inspiration",
		"title-short": "DesignAID",
		"URL": "https://dl.acm.org/doi/10.1145/3582269.3615596",
		"author": [
			{
				"family": "Cai",
				"given": "Alice"
			},
			{
				"family": "Rick",
				"given": "Steven R"
			},
			{
				"family": "Heyman",
				"given": "Jennifer L"
			},
			{
				"family": "Zhang",
				"given": "Yanxia"
			},
			{
				"family": "Filipowicz",
				"given": "Alexandre"
			},
			{
				"family": "Hong",
				"given": "Matthew"
			},
			{
				"family": "Klenk",
				"given": "Matt"
			},
			{
				"family": "Malone",
				"given": "Thomas"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					20
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2023",
					11,
					5
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/JV2TWB69",
		"type": "article",
		"abstract": "Previous efforts to support creative problem-solving have included (a) techniques (such as brainstorming and design thinking) to stimulate creative ideas, and (b) software tools to record and share these ideas. Now, generative AI technologies can suggest new ideas that might never have occurred to the users, and users can then select from these ideas or use them to stimulate even more ideas. Here, we describe such a system, Supermind Ideator. The system uses a large language model (GPT 3.5) and adds prompting, fine tuning, and a user interface specifically designed to help people use creative problem-solving techniques. Some of these techniques can be applied to any problem; others are specifically intended to help generate innovative ideas about how to design groups of people and/or computers (\"superminds\"). We also describe our early experiences with using this system and suggest ways it could be extended to support additional techniques for other specific problem-solving domains.",
		"DOI": "10.48550/arXiv.2311.01937",
		"license": "All rights reserved",
		"note": "arXiv:2311.01937 [cs]",
		"number": "arXiv:2311.01937",
		"publisher": "arXiv",
		"source": "arXiv.org",
		"title": "Supermind Ideator: Exploring generative AI to support creative problem-solving",
		"title-short": "Supermind Ideator",
		"URL": "http://arxiv.org/abs/2311.01937",
		"author": [
			{
				"family": "Rick",
				"given": "Steven R."
			},
			{
				"family": "Giacomelli",
				"given": "Gianni"
			},
			{
				"family": "Wen",
				"given": "Haoran"
			},
			{
				"family": "Laubacher",
				"given": "Robert J."
			},
			{
				"family": "Taubenslag",
				"given": "Nancy"
			},
			{
				"family": "Heyman",
				"given": "Jennifer L."
			},
			{
				"family": "Knicker",
				"given": "Max Sina"
			},
			{
				"family": "Jeddi",
				"given": "Younes"
			},
			{
				"family": "Maier",
				"given": "Hendrik"
			},
			{
				"family": "Dwyer",
				"given": "Stephen"
			},
			{
				"family": "Ragupathy",
				"given": "Pranav"
			},
			{
				"family": "Malone",
				"given": "Thomas W."
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2024",
					4,
					20
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2023",
					11,
					3
				]
			]
		}
	},
		{
		"id": "http://zotero.org/users/1296135/items/LALF2RF3",
		"type": "paper-conference",
		"abstract": "As crucial public functions are transferred to computer systems, emerging technologies have public implications that are often shaped beyond public influence and oversight. “Smart city” and “modernization” projects are just some examples of such transformations. This paper focuses on struggles over the acquisition, control, and maintenance of these public, digital infrastructures. We focus on the forms of HCI knowledge and practice that proved useful to a coalition of community organizations claiming rights of input into and political oversight over surveillance technology. Their claims were a response to their exclusion from decision-making about smart city implementation in San Diego. We offer tactics “from below” as a way to attune HCI to the needs and practices of those excluded from power over widespread technology infrastructures. Ultimately, we argue that HCI cultivates a variety of capacities beyond design and redesign that can strengthen struggles to shape real-world technologies from below.",
		"collection-title": "CHI '21",
		"container-title": "Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems",
		"DOI": "10.1145/3411764.3445314",
		"event-place": "New York, NY, USA",
		"ISBN": "978-1-4503-8096-6",
		"license": "All rights reserved",
		"page": "1–15",
		"publisher": "Association for Computing Machinery",
		"publisher-place": "New York, NY, USA",
		"source": "ACM Digital Library",
		"title": "HCI Tactics for Politics from Below: Meeting the Challenges of Smart Cities",
		"title-short": "HCI Tactics for Politics from Below",
		"URL": "https://doi.org/10.1145/3411764.3445314",
		"author": [
			{
				"family": "Whitney",
				"given": "Cedric Deslandes"
			},
			{
				"family": "Naval",
				"given": "Teresa"
			},
			{
				"family": "Quepons",
				"given": "Elizabeth"
			},
			{
				"family": "Singh",
				"given": "Simrandeep"
			},
			{
				"family": "Rick",
				"given": "Steven R"
			},
			{
				"family": "Irani",
				"given": "Lilly"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					10,
					13
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2021",
					5,
					6
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/Q9655Y5K",
		"type": "paper-conference",
		"abstract": "Many chronic diseases and common risks to elderly patients can be assessed and treated through standardized training and rehabilitation programs. Unfortunately, there is a need to make risk assessment and preventative care for the elderly more easily accessible as many programs either use specialized hardware or require human supervision. We seek to reduce the barrier to entry for patients through a portable application which enables fall risk prevention assessment and rehabilitation anywhere. Our work leverages the latest in machine learning and computer vision, accomplishing pose estimation and body tracking with a simple and ubiquitous web cam. Thus patients can be screened anywhere with the ability to get feedback in near-real time.",
		"collection-title": "IUI '19",
		"container-title": "Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion",
		"DOI": "10.1145/3308557.3308682",
		"event-place": "New York, NY, USA",
		"ISBN": "978-1-4503-6673-1",
		"license": "All rights reserved",
		"page": "105–106",
		"publisher": "Association for Computing Machinery",
		"publisher-place": "New York, NY, USA",
		"source": "ACM Digital Library",
		"title": "NeuroPose: geriatric rehabilitation in the home using a webcam and pose estimation",
		"title-short": "NeuroPose",
		"URL": "https://doi.org/10.1145/3308557.3308682",
		"author": [
			{
				"family": "Rick",
				"given": "Steven R."
			},
			{
				"family": "Bhaskaran",
				"given": "Shubha"
			},
			{
				"family": "Sun",
				"given": "Yajie"
			},
			{
				"family": "McEwen",
				"given": "Sarah"
			},
			{
				"family": "Weibel",
				"given": "Nadir"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					10,
					13
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					3,
					16
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/JI78JXWH",
		"type": "paper-conference",
		"abstract": "Maintaining good sleep hygiene is a constant challenge in modern lives. Sleep habits are hard to monitor and record, especially when most sleep monitoring programs overlook the necessity of calculating user input. This input is vital in order to change poor sleeping patterns, as it is difficult to identify the source of an individual's problems. Sleep tracking software also struggle with a lack of user transparency and interactivity leading individuals to mistrust the results these applications generate or otherwise not feel like the insights are actionable. To explore these issues, we designed an interventional chat bot to mediate information collection and interaction between end user and sleep monitoring technology. The SleepBot prompts users with simple questions that attempt to elicit insight into larger problems that contribute to poor sleep and help craft successful sleep hygiene behaviors. Text messaging based interaction eases the process as it is similar to talking with a friend, making for a unique environment in which the user is able to share personal data comfortably.",
		"collection-title": "IUI '19",
		"container-title": "Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion",
		"DOI": "10.1145/3308557.3308712",
		"event-place": "New York, NY, USA",
		"ISBN": "978-1-4503-6673-1",
		"license": "All rights reserved",
		"page": "107–108",
		"publisher": "Association for Computing Machinery",
		"publisher-place": "New York, NY, USA",
		"source": "ACM Digital Library",
		"title": "SleepBot: encouraging sleep hygiene using an intelligent chatbot",
		"title-short": "SleepBot",
		"URL": "https://doi.org/10.1145/3308557.3308712",
		"author": [
			{
				"family": "Rick",
				"given": "Steven R."
			},
			{
				"family": "Goldberg",
				"given": "Aaron Paul"
			},
			{
				"family": "Weibel",
				"given": "Nadir"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2022",
					10,
					13
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2019",
					3,
					16
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/Z9UAWTYR",
		"type": "paper-conference",
		"abstract": "Gestures, the visible body movements that are ubiquitous in human behavior, are key elements of natural communication. Understanding them is fundamental to designing computing applications with more natural forms of interaction. Both sign languages and everyday gestures reveal the rich signal capacity of this modality. However, although research is developing at fast pace, we still lack in-depth understanding of the elements that create the underlying symbolic signals. This is partly due to lack of tools for studying communicative movements in context. We introduce a novel approach to address this problem based on unobtrusive depth cameras and developed an infrastructure supporting naturalistic data collection. While we focus on sign language and gestures, the tools we developed are applicable for other types of body based research applications. We report on the quality of data collection, and we show how our approach can lead to novel insights and understanding of communicative movements.",
		"container-title": "2016 49th Hawaii International Conference on System Sciences (HICSS)",
		"DOI": "10.1109/HICSS.2016.82",
		"event-title": "2016 49th Hawaii International Conference on System Sciences (HICSS)",
		"license": "All rights reserved",
		"page": "610-619",
		"source": "IEEE Xplore",
		"title": "Hands That Speak: An Integrated Approach to Studying Complex Human Communicative Body Movements",
		"title-short": "Hands That Speak",
		"author": [
			{
				"family": "Weibel",
				"given": "N."
			},
			{
				"family": "Hwang",
				"given": "S."
			},
			{
				"family": "Rick",
				"given": "S."
			},
			{
				"family": "Sayyari",
				"given": "E."
			},
			{
				"family": "Lenzen",
				"given": "D."
			},
			{
				"family": "Hollan",
				"given": "J."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2016",
					1
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/RPB7S8FD",
		"type": "article-journal",
		"abstract": "We describe methods for capturing and analyzing EHR use and clinical workflow of physicians during outpatient encounters and relating activity to physicians' self-reported workload. We collected temporally-resolved activity data including audio, video, EHR activity, and eye-gaze along with post-visit assessments of workload. These data are then analyzed through a combination of manual content analysis and computational techniques to temporally align streams, providing a range of process measures of EHR usage, clinical workflow, and physician-patient communication. Data was collected from primary care and specialty clinics at the Veterans Administration San Diego Healthcare System and UCSD Health, who use Electronic Health Record (EHR) platforms, CPRS and Epic, respectively. Grouping visit activity by physician, site, specialty, and patient status enables rank-ordering activity factors by their correlation to physicians' subjective work-load as captured by NASA Task Load Index survey. We developed a coding scheme that enabled us to compare timing studies between CPRS and Epic and extract patient and visit complexity profiles. We identified similar patterns of EHR use and navigation at the 2 sites despite differences in functions, user interfaces and consequent coded representations. Both sites displayed similar proportions of EHR function use and navigation, and distribution of visit length, proportion of time physicians attended to EHRs (gaze), and subjective work-load as measured by the task load survey. We found that visit activity was highly variable across individual physicians, and the observed activity metrics ranged widely as correlates to subjective workload. We discuss implications of our study for methodology, clinical workflow and EHR redesign.",
		"container-title": "Journal of Biomedical Informatics",
		"DOI": "10.1016/j.jbi.2017.03.011",
		"ISSN": "1532-0464",
		"journalAbbreviation": "Journal of Biomedical Informatics",
		"license": "All rights reserved",
		"page": "135-149",
		"source": "ScienceDirect",
		"title": "Physician activity during outpatient visits and subjective workload",
		"URL": "http://www.sciencedirect.com/science/article/pii/S1532046417300618",
		"volume": "69",
		"author": [
			{
				"family": "Calvitti",
				"given": "Alan"
			},
			{
				"family": "Hochheiser",
				"given": "Harry"
			},
			{
				"family": "Ashfaq",
				"given": "Shazia"
			},
			{
				"family": "Bell",
				"given": "Kristin"
			},
			{
				"family": "Chen",
				"given": "Yunan"
			},
			{
				"family": "El Kareh",
				"given": "Robert"
			},
			{
				"family": "Gabuzda",
				"given": "Mark T."
			},
			{
				"family": "Liu",
				"given": "Lin"
			},
			{
				"family": "Mortensen",
				"given": "Sara"
			},
			{
				"family": "Pandey",
				"given": "Braj"
			},
			{
				"family": "Rick",
				"given": "Steven"
			},
			{
				"family": "Street",
				"given": "Richard L."
			},
			{
				"family": "Weibel",
				"given": "Nadir"
			},
			{
				"family": "Weir",
				"given": "Charlene"
			},
			{
				"family": "Agha",
				"given": "Zia"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2018",
					12,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017",
					5,
					1
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/77ENNJ5H",
		"type": "paper-conference",
		"abstract": "Recent technology advances in both Virtual Reality and Augmented Reality are creating an opportunity for a paradigm shift in the design of human-computer interaction systems. Delving into the Reality-Virtuality Continuum, we find Mixed Reality - systems designed to augment the physical world with virtual entities that embody characteristics of real world objects. In the medical field, Mixed Reality systems can overlay real-time and spatially accurate results onto a patient's body without the need for external screens. The complexity of these systems previously required specialized prototypes, but newly available commercial products like the Microsoft HoloLens make the technology more available. Through a combination of literature review, expert analysis, and prototyping we explore the use of Mixed Reality in healthcare. From the experience of prototyping Patiently and HoloSim, two applications for augmenting medical training, we outline considerations for the future design and development of virtual interfaces grounded in reality.",
		"collection-title": "CHI EA '17",
		"container-title": "Proceedings of the 2017 CHI Conference Extended Abstracts on Human Factors in Computing Systems",
		"DOI": "10.1145/3027063.3053273",
		"event-place": "New York, NY, USA",
		"ISBN": "978-1-4503-4656-6",
		"license": "All rights reserved",
		"page": "2591–2598",
		"publisher": "ACM",
		"publisher-place": "New York, NY, USA",
		"source": "ACM Digital Library",
		"title": "Exploring Mixed Reality in Specialized Surgical Environments",
		"URL": "http://doi.acm.org/10.1145/3027063.3053273",
		"author": [
			{
				"family": "Gasques Rodrigues",
				"given": "Danilo"
			},
			{
				"family": "Jain",
				"given": "Ankur"
			},
			{
				"family": "Rick",
				"given": "Steven R."
			},
			{
				"family": "Shangley",
				"given": "Liu"
			},
			{
				"family": "Suresh",
				"given": "Preetham"
			},
			{
				"family": "Weibel",
				"given": "Nadir"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2018",
					12,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2017"
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/JWRZGTZH",
		"type": "article-journal",
		"abstract": "Electronic Health Records (EHRs) have increased the utility and portability of health information by storing it in structured formats. However, EHRs separate this structured data from the rich, free-text descriptions of clinical notes. The ultimate objective of our research is to develop an interactive progress note that unifies entry, access, and retrieval of structured and unstructured health information. In this study we present the design and subsequent testing with eight clinicians of a core element of this envisioned note: free-text order entry. Clinicians saw this new order-entry paradigm as a way to save time and preserve data quality by reducing double-documentation. However, they wanted the prototype to recognize more diverse types of shorthand and apply default values to fields that remain fairly constant across orders, such as number of refills and pickup location. Future work will test more complex orders, such as cascading orders, with a broader range of clinicians.",
		"container-title": "AMIA Annual Symposium Proceedings",
		"ISSN": "1942-597X",
		"journalAbbreviation": "AMIA Annu Symp Proc",
		"license": "All rights reserved",
		"note": "PMID: 26958249\nPMCID: PMC4765684",
		"page": "1103-1110",
		"source": "PubMed Central",
		"title": "Validating free-text order entry for a note-centric EHR",
		"URL": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4765684/",
		"volume": "2015",
		"author": [
			{
				"family": "Rule",
				"given": "Adam"
			},
			{
				"family": "Rick",
				"given": "Steven"
			},
			{
				"family": "Chiu",
				"given": "Michael"
			},
			{
				"family": "Rios",
				"given": "Phillip"
			},
			{
				"family": "Ashfaq",
				"given": "Shazia"
			},
			{
				"family": "Calvitti",
				"given": "Alan"
			},
			{
				"family": "Chan",
				"given": "Wesley"
			},
			{
				"family": "Weibel",
				"given": "Nadir"
			},
			{
				"family": "Agha",
				"given": "Zia"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2018",
					12,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					11,
					5
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/YQ9U5FEJ",
		"type": "article-journal",
		"abstract": "BackgroundEvidence is mixed regarding how physicians' use of the electronic health record (EHR) affects communication in medical encounters.ObjectiveTo investigate whether the different ways physicians interact with the computer (mouse clicks, key strokes, and gaze) vary in their effects on patient participation in the consultation, physicians’ efforts to facilitate patient involvement, and silence.DesignCross-sectional, observational study of video and event recordings of primary care and specialty consultations.ParticipantsThirty-two physicians and 217 patients.Main MeasuresPredictor variables included measures of physician interaction with the EHR (mouse clicks, key strokes, gaze). Outcome measures included active patient participation (asking questions, stating preferences, expressing concerns), physician facilitation of patient involvement (partnership-building and supportive talk), and silence.Key ResultsPatients were less active participants in consultations in which physicians engaged in more keyboard activity (b = −0.002, SE = 0.001, p = 0.02). More physician gaze at the computer was associated with more silence in the encounter (b = 0.21, SE = 0.09, p = 0.02). Physicians’ facilitative communication, which predicted more active patient participation (b = 0.65, SE = 0.14, p < 0.001), was not related to EHR activity measures.ConclusionsPatients may be more reluctant to actively participate in medical encounters when physicians are more physically engaged with the computer (e.g., keyboard activity) than when their behavior is less demonstrative (e.g., gazing at EHR). Using easy to deploy communication tactics (e.g., asking about a patient’s thoughts and concerns, social conversation) while working on the computer can help physicians engage patients as well as maintain conversational flow.",
		"container-title": "Journal of General Internal Medicine",
		"DOI": "10.1007/s11606-017-4228-2",
		"ISSN": "1525-1497",
		"issue": "4",
		"journalAbbreviation": "J GEN INTERN MED",
		"language": "en",
		"license": "All rights reserved",
		"page": "423-428",
		"source": "Springer Link",
		"title": "Keystrokes, Mouse Clicks, and Gazing at the Computer: How Physician Interaction with the EHR Affects Patient Participation",
		"title-short": "Keystrokes, Mouse Clicks, and Gazing at the Computer",
		"URL": "https://doi.org/10.1007/s11606-017-4228-2",
		"volume": "33",
		"author": [
			{
				"family": "Street",
				"given": "Richard L."
			},
			{
				"family": "Liu",
				"given": "Lin"
			},
			{
				"family": "Farber",
				"given": "Neil J."
			},
			{
				"family": "Chen",
				"given": "Yunan"
			},
			{
				"family": "Calvitti",
				"given": "Alan"
			},
			{
				"family": "Weibel",
				"given": "Nadir"
			},
			{
				"family": "Gabuzda",
				"given": "Mark T."
			},
			{
				"family": "Bell",
				"given": "Kristin"
			},
			{
				"family": "Gray",
				"given": "Barbara"
			},
			{
				"family": "Rick",
				"given": "Steven"
			},
			{
				"family": "Ashfaq",
				"given": "Shazia"
			},
			{
				"family": "Agha",
				"given": "Zia"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2018",
					12,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2018",
					4,
					1
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/TQ8BHMRL",
		"type": "paper-conference",
		"abstract": "Electronic medical records (EMRs) are changing the way physicians work and how medical staff care for patients. While their widespread adoption promise many benefits and computationally powerful features for end users, they may also carry with them other unintended and troubling consequences. As part of a larger ongoing research study, we deployed an unobtrusive eye tracker in outpatient clinics to observe how physicians use their EMRs. We report on our experiences and we derive a methodology for successful eye tracking data collection in the clinic. Our results highlight multiple applications for the quantitative and qualitative assessment of EMR interfaces from eye tracking data collected in situ. We describe one of these applications, the association of eye movements with the specific task that physicians engage with in the EMR, and we discuss both next steps and future application of these results.",
		"container-title": "2015 9th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth)",
		"DOI": "10.4108/icst.pervasivehealth.2015.259276",
		"event-title": "2015 9th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth)",
		"license": "All rights reserved",
		"page": "213-216",
		"source": "IEEE Xplore",
		"title": "Eyes on the clinic: Accelerating meaningful interface analysis through unobtrusive eye tracking",
		"title-short": "Eyes on the clinic",
		"author": [
			{
				"family": "Rick",
				"given": "S."
			},
			{
				"family": "Calvitti",
				"given": "A."
			},
			{
				"family": "Agha",
				"given": "Z."
			},
			{
				"family": "Weibel",
				"given": "N."
			}
		],
		"issued": {
			"date-parts": [
				[
					"2015",
					5
				]
			]
		}
	},
	{
		"id": "http://zotero.org/users/1296135/items/RCINIMKF",
		"type": "article-journal",
		"abstract": "Patient-centered healthcare and increased efficiency are major goals of modern medicine, and physician---patient interaction and communication are a cornerstone of clinical encounters. The introduction of the electronic health record (EHR) has been a key component in shaping not only organization, clinical workflow and ultimately physicians' clinical decision making, but also patient---physician communication in the medical office. In order to inform the design of future EHR interfaces and assess their impact on patient-centered healthcare, designers and researchers must understand the multimodal nature of the complex physician---patient---EHR system interaction. However, characterizing multimodal activity is difficult and expensive, often requiring manual coding of hours of video data. We present our Lab-in-a-Box solution that enables the capture of multimodal activity in real-world settings. We focus here on the medical office where our Lab-in-a-Box system exploits a range of sensors to track computer-based activity, speech interaction, visual attention and body movements, and automatically synchronize and segment this data. The fusion of multiple sensors allows us to derive initial activity segmentation and to visualize it for further interactive analysis. By empowering researchers with cutting-edge data collection tools and accelerating analysis of multimodal activity in the medical office, our Lab-in-a-Box has the potential to uncover important insights and inform the next generation of Health IT systems.",
		"container-title": "Personal Ubiquitous Comput.",
		"DOI": "10.1007/s00779-014-0821-0",
		"ISSN": "1617-4909",
		"issue": "2",
		"license": "All rights reserved",
		"page": "317–334",
		"source": "ACM Digital Library",
		"title": "LAB-IN-A-BOX: Semi-automatic Tracking of Activity in the Medical Office",
		"title-short": "LAB-IN-A-BOX",
		"URL": "http://dx.doi.org/10.1007/s00779-014-0821-0",
		"volume": "19",
		"author": [
			{
				"family": "Weibel",
				"given": "Nadir"
			},
			{
				"family": "Rick",
				"given": "Steven"
			},
			{
				"family": "Emmenegger",
				"given": "Colleen"
			},
			{
				"family": "Ashfaq",
				"given": "Shazia"
			},
			{
				"family": "Calvitti",
				"given": "Alan"
			},
			{
				"family": "Agha",
				"given": "Zia"
			}
		],
		"accessed": {
			"date-parts": [
				[
					"2018",
					12,
					8
				]
			]
		},
		"issued": {
			"date-parts": [
				[
					"2015",
					2
				]
			]
		}
	}
]